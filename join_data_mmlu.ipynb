{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba9742a22fd1270",
   "metadata": {},
   "source": [
    "# Block 1 & 2 (Merge Output CSVs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:26:38.634731Z",
     "start_time": "2024-07-29T09:26:38.614258Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_file_name = 'mmlu-dev'  # Base file name to match\n",
    "folder_path = f'outputs/{base_file_name}'  # Folder containing the CSV files\n",
    "\n",
    "\n",
    "def collect_csvs():\n",
    "    pattern = re.compile(rf\"^(\\d+)-{re.escape(base_file_name)}\\.csv$\")\n",
    "    csv_files = [file for file in os.listdir(folder_path) if pattern.match(file)]\n",
    "    csv_files.sort(key=lambda x: int(re.findall(r'^\\d+', x)[0]))\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "csv_files = collect_csvs()\n",
    "\n",
    "\n",
    "def combine_csv_files():\n",
    "    df = pd.concat([pd.read_csv(os.path.join(folder_path, file), na_filter=False) for file in csv_files], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f53bf4c25125ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:27:02.450529Z",
     "start_time": "2024-07-29T09:26:40.581592Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_df = combine_csv_files()\n",
    "merged_df = merged_df.sort_values('Id').drop_duplicates(subset=['Id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "merged_df['Original Choices'] = merged_df[['Original Choice 1', 'Original Choice 2', 'Original Choice 3', 'Original Choice 4']].values.tolist()\n",
    "merged_df['Translated Choices'] = merged_df[['Translated Choice 1', 'Translated Choice 2', 'Translated Choice 3', 'Translated Choice 4']].values.tolist()\n",
    "\n",
    "merged_df['Original Choices'] = merged_df['Original Choices'].apply(np.array)\n",
    "merged_df['Translated Choices'] = merged_df['Translated Choices'].apply(np.array)\n",
    "\n",
    "merged_df = merged_df.drop(columns=['Original Choice 1', 'Original Choice 2', 'Original Choice 3', 'Original Choice 4', \n",
    "                      'Translated Choice 1', 'Translated Choice 2', 'Translated Choice 3', 'Translated Choice 4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74182728",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2722be0f653e7b",
   "metadata": {},
   "source": [
    "# Block 3 (Compare Dataset Length with Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8ea9d8d5f1268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:18:32.920564Z",
     "start_time": "2024-07-29T09:18:28.894570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Original Dataset to Verify\n",
    "import utils\n",
    "from datasets import load_dataset\n",
    "from termcolor import colored\n",
    "\n",
    "original_subset_name = 'dev'\n",
    "\n",
    "full_dataset = load_dataset(\"cais/mmlu\", \"all\")\n",
    "dataset = full_dataset[original_subset_name].to_pandas()\n",
    "\n",
    "\n",
    "def check_dataset_length(df: pd.DataFrame, dataset: pd.DataFrame) -> bool:\n",
    "    length_check = len(df) == len(dataset)\n",
    "    if length_check:\n",
    "        print(colored(\"Length check passed.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(f\"Length check failed. Translated: {len(df)}, Original: {len(dataset)}\", \"red\"))\n",
    "    return length_check\n",
    "\n",
    "\n",
    "print(len(merged_df), len(dataset))\n",
    "length_check = check_dataset_length(merged_df, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530577f65fb89b1",
   "metadata": {},
   "source": [
    "# Block 4 (Verify Row Continuity of the Translated Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6628ba16d717b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:18:39.668049Z",
     "start_time": "2024-07-29T09:18:39.556104Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_ids = []\n",
    "extra_ids = []\n",
    "\n",
    "def check_row_continuity(df: pd.DataFrame, id_column: str = 'Id') -> bool:\n",
    "    global missing_ids, extra_ids\n",
    "\n",
    "    expected_ids = set(df[id_column])\n",
    "    actual_ids = set(range(len(dataset)))\n",
    "\n",
    "    extra_ids = sorted(expected_ids - actual_ids)\n",
    "    missing_ids = sorted(actual_ids - expected_ids)\n",
    "\n",
    "    if missing_ids:\n",
    "        print(colored(f\"Missing IDs: {sorted(missing_ids)}\", \"red\"))\n",
    "\n",
    "    if extra_ids:\n",
    "        print(colored(f\"Extra IDs: {sorted(extra_ids)}\", \"red\"))\n",
    "\n",
    "    if missing_ids or extra_ids:\n",
    "        return False\n",
    "    else:\n",
    "        print(colored(\"All rows are present and in order.\", \"green\"))\n",
    "        return True\n",
    "\n",
    "\n",
    "db_continuity = check_row_continuity(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67659dd082e6cde5",
   "metadata": {},
   "source": [
    "# Block 5,6,7 (Column Data Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f2a7c2f37e068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:27:03.052919Z",
     "start_time": "2024-07-29T09:27:02.454479Z"
    }
   },
   "outputs": [],
   "source": [
    "assert check_dataset_length(merged_df, dataset)\n",
    "\n",
    "\n",
    "def compare_columns(df1: pd.DataFrame, df2: pd.DataFrame, df1_col_name: str, df2_col_name: str):\n",
    "    comparison_df = pd.DataFrame({\n",
    "        f'{df1_col_name}': df1[df1_col_name],\n",
    "        f'{df2_col_name}': df2[df2_col_name],\n",
    "        'match': df1.apply(lambda row: np.array_equal(row[df1_col_name], df2.at[row.name, df2_col_name]), axis=1)\n",
    "    })\n",
    "    mismatched_df = comparison_df[~comparison_df['match']]\n",
    "    if len(mismatched_df) > 0:\n",
    "        print(colored(f\"[{df2_col_name}] Some entries didn't match with the originals\", \"red\"))\n",
    "    else:\n",
    "        print(colored(f\"[{df2_col_name}] Data comparison Successful.\", \"green\"))\n",
    "\n",
    "    return mismatched_df\n",
    "\n",
    "\n",
    "def validate_columns():\n",
    "    input_col_mismatches = compare_columns(merged_df, dataset, 'Original Question', 'question')\n",
    "    target_col_mismatches = compare_columns(merged_df, dataset, 'Original Choices', 'choices')\n",
    "\n",
    "    if input_col_mismatches.empty and target_col_mismatches.empty:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "validate_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce797480461f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:27:09.876554Z",
     "start_time": "2024-07-29T09:27:09.567622Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_columns(merged_df, dataset, 'Original Input', 'inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3335e3f6d732a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:27:11.818057Z",
     "start_time": "2024-07-29T09:27:11.670333Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_columns(merged_df, dataset, 'Original Target', 'targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe47df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_length_df = merged_df[merged_df.apply(lambda row: len(row['Original Choices']) != len(row['Translated Choices']), axis=1)]\n",
    "\n",
    "if len(mismatched_length_df) > 0:\n",
    "    print(colored(\"Some entries have mismatched lengths between Original Choices and Translated Choices\", \"red\"))\n",
    "    for index, row in mismatched_length_df.iterrows():\n",
    "        print(f\"Row {index}: Original Choices Length = {len(row['Original Choices'])}, Translated Choices Length = {len(row['Translated Choices'])}\")\n",
    "else:\n",
    "    print(colored(\"Length comparison between Original Choices and Translated Choices is successful.\", \"green\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839aafa843beb692",
   "metadata": {},
   "source": [
    "# Block 8 (Combine Metadata Records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d5cd655d0523d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:39:10.354272Z",
     "start_time": "2024-07-29T09:39:10.112770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding metadata to the merged dataset\n",
    "dataset_metadata = dataset.loc[:, ~dataset.columns.isin(['question', 'choices'])]\n",
    "print(f\"Metadata length: {len(dataset_metadata)}\")\n",
    "\n",
    "assert check_row_continuity(merged_df)\n",
    "assert validate_columns()\n",
    "assert len(dataset_metadata) == len(merged_df)\n",
    "\n",
    "merged_df_with_metadata = pd.concat([merged_df, dataset_metadata], axis=1)\n",
    "\n",
    "merged_df_with_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebd3797056f9a7",
   "metadata": {},
   "source": [
    "# Block 9 (Save as Parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe38ed926db9d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:41:11.808389Z",
     "start_time": "2024-07-29T09:41:06.506335Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "parquet_file_name = \"mmlu-dev\"  # Name of the parquet file to save\n",
    "\n",
    "assert check_row_continuity(merged_df_with_metadata)\n",
    "assert validate_columns()\n",
    "\n",
    "updated_df = merged_df_with_metadata.drop(columns='Id')\n",
    "\n",
    "\n",
    "def save_as_parquet(df: pd.DataFrame, file_name: str) -> str:\n",
    "    parquet_path = f\"translated_datasets/{file_name}.parquet\"\n",
    "    if os.path.exists(parquet_path):\n",
    "        print(f\"File {parquet_path} already exists. Not overwriting.\")\n",
    "        return parquet_path\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    print(f\"Data saved as {parquet_path}\")\n",
    "    return parquet_path\n",
    "\n",
    "\n",
    "parquet_path = save_as_parquet(updated_df, parquet_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c07cbceeecad6e",
   "metadata": {},
   "source": [
    "# Block 10 (Upload to Hugging Face)\n",
    "<em>(Make sure to login with `huggingface-cli` before running this block)</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca138ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parquet_file_name = \"mmlu-auxiliary_train\" # Uncomment if you want to change the parquet file name\n",
    "parquet_path = f\"translated_datasets/{parquet_file_name}.parquet\"\n",
    "print(f\"Loading the saved parquet file: {parquet_path}\")\n",
    "saved_df = pd.read_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c967bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5b01df129318a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:48:48.081158Z",
     "start_time": "2024-07-29T09:48:27.489985Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "repo_id = \"0xAIT/sinhala-MMLU\"\n",
    "subset_name = \"all\" # Make sure to change this to the subset name (Use underscores instead of hyphens e.g. \"flan_zsopt\")\n",
    "split_name = \"auxiliary_train\" # Make sure to change this to the subset name (Use underscores instead of hyphens e.g. \"flan_zsopt\")\n",
    "\n",
    "dataset = Dataset.from_pandas(saved_df)\n",
    "dataset.push_to_hub(repo_id, config_name=subset_name, split=split_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
